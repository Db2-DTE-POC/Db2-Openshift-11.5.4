{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Credit Card Fraud using Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_db\n",
    "import ibm_db_dbi\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Db2 Instance Created!\n"
     ]
    }
   ],
   "source": [
    "# Connect to Db2\n",
    "t0=time()\n",
    "conn_str = \"DATABASE=CRCARD;\" + \\\n",
    "           \"HOSTNAME=entb06.canlab.ibm.com;\"+ \\\n",
    "           \"PROTOCOL=TCPIP;\"  + \\\n",
    "           \"PORT=50000;\" + \\\n",
    "           \"UID=PERFPOL2;\" + \\\n",
    "           \"PWD=blu4speed;\" \n",
    "\n",
    "\n",
    "ibm_db_conn = ibm_db.connect(conn_str,\"\",\"\")\n",
    "conn = ibm_db_dbi.Connection(ibm_db_conn)\n",
    "print('Connection to Db2 Instance Created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pulled test data from Db2!\n"
     ]
    }
   ],
   "source": [
    "## Load testing data from Db2\n",
    "sql = 'SELECT * FROM CC_PREDICT_SCALED' #CREDIT_CARD_PREDICTION\n",
    "X_test = pd.read_sql(sql,conn)\n",
    "print('Successfully pulled test data from Db2!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load model + scaler\n",
    "saved_model = load('test/saved_model.joblib') #/data2/home/apu/saved_model.joblib\n",
    "print('Model loaded successfully!')\n",
    "# saved_scaler = load('test/saved_scaler.joblib') #/data2/home/apu/saved_scaler.joblib\n",
    "# print('Scaler loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale AMOUNT column\n",
    "# X_test['AMOUNT_SCALED'] = saved_scaler.transform(X_test['AMOUNT_SCALED'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `num_rows` variable to set prediction batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 6.246 s to make a prediction on 100000 instances.\n"
     ]
    }
   ],
   "source": [
    "# Use saved model to make a prediction on the test set\n",
    "num_rows=100000\n",
    "y_pred_saved = saved_model.predict(X_test.sample(n=num_rows))\n",
    "t1 = time()\n",
    "tot_time = t1-t0\n",
    "print('It took', round(tot_time, 3),'s to make a prediction on', num_rows,'instances.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
